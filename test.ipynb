{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2b32df-6707-4295-aa57-33e7cabb1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e77428-9423-46f7-b1ba-3fbec1a063dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import lmdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001d659-35d0-4e76-b72b-009225136908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    transform = v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((128, 128)),\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371ba07-39fd-4267-ab7e-5523c38304ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('image.jpeg')\n",
    "image = load_image(path)\n",
    "fft_image = fft.fft2(image, dim=(-2,-1))\n",
    "fft_shift = fft.fftshift(fft_image, dim=(-2,-1))\n",
    "magnitude = torch.log(torch.abs(fft_shift)+ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a3132-f059-48fb-b2f3-97e1b26919ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].set_title('Original')\n",
    "axes[0].imshow(image.permute(1,2,0), cmap='gray')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].set_title('Magnitude Spectrum')\n",
    "axes[1].imshow(magnitude.permute(1,2,0), cmap='gray')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fft_img.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ff60e-e687-459e-b81d-9958be9860bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = image.squeeze(0).shape\n",
    "crow, ccol = rows//2, cols//2\n",
    "radius = 20\n",
    "\n",
    "mask = torch.zeros((rows, cols))\n",
    "y, x = torch.meshgrid(torch.arange(0, rows), torch.arange(0, cols), indexing='ij')\n",
    "mask_area = torch.sqrt((x - ccol)**2 + (y - crow)**2)\n",
    "\n",
    "mask_h = (mask_area > radius).float()\n",
    "mask_l = (mask_area <= radius).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d11668-7995-4c6c-88c5-c44d35274ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_filtered_fft = fft_shift * mask_h\n",
    "high_filtered_image = torch.abs(fft.ifft2(fft.ifftshift(high_filtered_fft)))\n",
    "magnitude_high_filtered_image = torch.log(torch.abs(high_filtered_fft)+ 1)\n",
    "\n",
    "low_filtered_fft = fft_shift * mask_l\n",
    "low_filtered_image = torch.abs(fft.ifft2(fft.ifftshift(low_filtered_fft)))\n",
    "magnitude_low_filtered_image = torch.log(torch.abs(low_filtered_fft)+ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876851e-e949-4e01-a1c2-c93f7676503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(15, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].set_title('Original')\n",
    "axes[0].imshow(image.permute(1,2,0), cmap='gray')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].set_title('FFT')\n",
    "axes[1].imshow(magnitude.permute(1,2,0), cmap='gray')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].set_title('Low Pass Filter')\n",
    "axes[2].imshow(magnitude_low_filtered_image.permute(1,2,0), cmap='gray')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].set_title('High Pass Filter')\n",
    "axes[3].imshow(magnitude_high_filtered_image.permute(1,2,0), cmap='gray')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].set_title('Low Filter Image')\n",
    "axes[4].imshow(low_filtered_image.permute(1,2,0), cmap='gray')\n",
    "axes[4].axis('off')\n",
    "\n",
    "axes[5].set_title('High Filter Image')\n",
    "axes[5].imshow(high_filtered_image.permute(1,2,0), cmap='gray')\n",
    "axes[5].axis('off')\n",
    "\n",
    "axes[6].set_title('Low Filter Mask')\n",
    "axes[6].imshow(mask_l, cmap='gray')\n",
    "axes[6].axis('off')\n",
    "\n",
    "axes[7].set_title('High Filter Mask')\n",
    "axes[7].imshow(mask_h, cmap='gray')\n",
    "axes[7].axis('off')\n",
    "\n",
    "plt.savefig('filter_img.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151e777-6d06-4f5e-920b-031f58c2b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Original Image\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].imshow(image.squeeze(), cmap='gray')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# FFT Spectrum\n",
    "axes[1].set_title('FFT Magnitude Spectrum')\n",
    "axes[1].imshow(magnitude.squeeze(), cmap='gray')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Low-Pass Filtered Spectrum\n",
    "axes[2].set_title('Low-Pass Filter Spectrum')\n",
    "axes[2].imshow(magnitude_low_filtered.squeeze(), cmap='gray')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# High-Pass Filtered Spectrum\n",
    "axes[3].set_title('High-Pass Filter Spectrum')\n",
    "axes[3].imshow(magnitude_high_filtered.squeeze(), cmap='gray')\n",
    "axes[3].axis('off')\n",
    "\n",
    "# Inverse FFT (Reconstructed) Images\n",
    "axes[4].set_title('Reconstructed Low-Pass Image')\n",
    "axes[4].imshow(low_filtered_image.squeeze(), cmap='gray')\n",
    "axes[4].axis('off')\n",
    "\n",
    "axes[5].set_title('Reconstructed High-Pass Image')\n",
    "axes[5].imshow(high_filtered_image.squeeze(), cmap='gray')\n",
    "axes[5].axis('off')\n",
    "\n",
    "# Show Filters\n",
    "axes[6].set_title('Low-Pass Mask')\n",
    "axes[6].imshow(mask_l, cmap='gray')\n",
    "axes[6].axis('off')\n",
    "\n",
    "axes[7].set_title('High-Pass Mask')\n",
    "axes[7].imshow(mask_h, cmap='gray')\n",
    "axes[7].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f307b8-d205-4cdc-92c0-aa855c0d9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.googlenet(weights='GoogLeNet_Weights.DEFAULT')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96798613-598e-4334-a87e-55c3d8dc1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_layer(layer):\n",
    "    fft_conv = FFTConvNet(layer, 'low')\n",
    "    return fft_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96fdaf-7734-48f5-80c0-65f8f0929dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the output channels of the original Conv2d layer\n",
    "original_conv = model.inception3a.branch2[0].conv\n",
    "print(\"Original Conv2d output channels:\", original_conv.out_channels)\n",
    "\n",
    "# Replace the Conv2d layer with FFTConvNet\n",
    "fft_conv = change_layer(original_conv).to(device)\n",
    "model.inception3a.branch2[0].conv = fft_conv\n",
    "\n",
    "# Verify the output channels of the FFTConvNet layer\n",
    "print(\"FFTConvNet output channels:\", fft_conv.conv_layer.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6941c6-6519-4f05-9019-8cedcb60839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd728d13-0298-4cfd-8f5d-1fceb81a6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd15842-6338-40d9-8386-4026694c7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    ")\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(9216, out_features=1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=1024, out_features=512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(in_features=512, out_features=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292c318-d1e7-41ed-bb9e-b7794a4dece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17961a-201e-410f-80aa-acb0f9db9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 227, 227)\n",
    "outputs = model(dummy_input)\n",
    "print(\"Outputs: \", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efc941-41ef-4baf-b19e-13bb48769ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(weights=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda:nvidia",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
