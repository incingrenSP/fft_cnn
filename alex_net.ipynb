{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cd6d99-3e63-4dd9-8881-8412153fe803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:59:28.237291Z",
     "start_time": "2025-02-03T03:59:11.050211Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ba4918-cc5c-4d47-8ae1-b8e8b538174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff74d9a-b2fd-47b2-a955-2e8c3dfc6c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:59:28.357971Z",
     "start_time": "2025-02-03T03:59:28.253251Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import lmdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b640dbb-6595-4604-8c01-c9e5714688ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.FFTConv import *\n",
    "from src.ImageHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e6c79a-1512-408e-83b5-2eb10805c172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:59:30.554130Z",
     "start_time": "2025-02-03T03:59:29.241877Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "REBUILD_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42e952b-70b3-412c-906a-bf5eb243f3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:16:56.826949Z",
     "start_time": "2025-02-03T04:12:25.512915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train dataset\n",
      "Loaded val dataset\n"
     ]
    }
   ],
   "source": [
    "lmdb_path = os.path.join('lmdb')\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    image_path = os.path.join('data', 'train_set')\n",
    "    train_data = ImageDataset(image_path=image_path, device=device, lmdb_path=lmdb_path, save_lmdb=True)\n",
    "    \n",
    "    image_path = os.path.join('data', 'val_set')\n",
    "    val_data = ImageDataset(image_path=image_path, device=device, lmdb_path=lmdb_path, save_lmdb=True, mode=\"val\")\n",
    "    REBUILD_DATA = False\n",
    "else:\n",
    "    train_data = ImageDataset(image_path=None, device=device, lmdb_path=lmdb_path, save_lmdb=False)\n",
    "    val_data = ImageDataset(image_path=None, device=device, lmdb_path=lmdb_path, save_lmdb=False, mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6b302d-38c9-4b48-bfb1-1f06532b5e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:28:55.654472Z",
     "start_time": "2025-02-03T04:28:55.641471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9959, 4200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099eba50-6812-443c-9a7d-158d802e0eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:28:56.957883Z",
     "start_time": "2025-02-03T04:28:56.947912Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle=True, pin_memory=True)\n",
    "val_dl = DataLoader(val_data, batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66de5850-3dd2-44b7-9ac2-da6d90717ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:28:57.391172Z",
     "start_time": "2025-02-03T04:28:57.385188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  torch.Size([16, 3, 128, 128])\n",
      "Label shape:  torch.Size([16])\n",
      "Image shape:  torch.Size([16, 3, 128, 128])\n",
      "Label shape:  torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    labels = labels.squeeze().long()\n",
    "    print(\"Image shape: \", images.shape)\n",
    "    print(\"Label shape: \", labels.shape)\n",
    "    break\n",
    "\n",
    "for images, labels in val_dl:\n",
    "    labels = labels.squeeze().long()\n",
    "    print(\"Image shape: \", images.shape)\n",
    "    print(\"Label shape: \", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9329e0-93b3-4278-a418-da2790e5af9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:28:59.223593Z",
     "start_time": "2025-02-03T04:28:58.583273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Layers replaced:  1\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "weight_decay = 5e-4\n",
    "# momentum = 0.9\n",
    "\n",
    "model = FFTAlex(apply_fft=True, device=device, IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f1de52-d4da-4499-b723-aae1369cba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  tensor([[-0.0276, -0.0251, -0.0691]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Testing if model is working\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "outputs = model(dummy_input)\n",
    "print(\"Output shape: \", outputs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46972a1a-cfaa-4979-a1ff-8882816f9a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:29:00.808188Z",
     "start_time": "2025-02-03T04:29:00.800208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0005\n",
      ") CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = optim.AdamW(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "print(optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdeb8546-9979-42ff-964f-957934cc5d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:29:01.518272Z",
     "start_time": "2025-02-03T04:29:01.511291Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, loss_fn, optimizer, scheduler, epochs, name, device):\n",
    "    best_acc = 0.0\n",
    "    tr_acc_list = []\n",
    "    val_acc_list = []\n",
    "    \n",
    "    # Mixed precision training\n",
    "    scaler = torch.GradScaler(device)  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_dl):\n",
    "            # Move data to GPU\n",
    "            labels = labels.squeeze().long()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.autocast(device):\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Compute metrics\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_corrects / total_samples\n",
    "        tr_acc_list.append(epoch_acc.cpu().item())\n",
    "        print(f\"Training Loss: {epoch_loss:0.6f}, Training Accuracy: {epoch_acc:0.6f}\")\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss, val_acc = validate(model, val_dl, loss_fn, device)\n",
    "        val_acc_list.append(val_acc.cpu().item())\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            model.save_model_dict(os.path.join(\"models\", \"alex\"), f\"{name}_model.pth\")\n",
    "            # torch.save(model.state_dict(), os.path.join(\"models\", \"alex\", f\"{name}_model.pth\"))\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Training Complete.')\n",
    "    return tr_acc_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a338917-bc80-4858-b156-d3ea44083e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_dl, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_dl):\n",
    "            # Move data to GPU\n",
    "            labels = labels.squeeze().long()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs.data, labels)\n",
    "\n",
    "            # Compute metrics\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        val_loss = running_loss / total_samples\n",
    "        val_acc = running_corrects / total_samples\n",
    "        print(f\"Validation Loss: {val_loss:0.6f}, Validation Accuracy: {val_acc:0.6f}\")\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60b82c5-1385-4a6a-bf83-dc6f2b61fc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T04:29:02.222244Z",
     "start_time": "2025-02-03T04:29:02.216260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 623/623 [01:56<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.620304, Training Accuracy: 0.718345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [00:18<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.504076, Validation Accuracy: 0.764762\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 623/623 [02:08<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.489365, Training Accuracy: 0.784818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [00:18<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.474654, Validation Accuracy: 0.779762\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 623/623 [02:05<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.440170, Training Accuracy: 0.810121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [00:19<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.454747, Validation Accuracy: 0.791429\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 623/623 [02:08<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.401637, Training Accuracy: 0.827894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [00:18<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.438481, Validation Accuracy: 0.798333\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████▉                                       | 319/623 [02:38<02:30,  2.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft_alex\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m tr_acc_list, val_acc_list \u001b[38;5;241m=\u001b[39m train(model, train_dl, val_dl, loss_fn, optimizer, scheduler, epochs\u001b[38;5;241m=\u001b[39mepochs, name\u001b[38;5;241m=\u001b[39mname, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dl, val_dl, loss_fn, optimizer, scheduler, epochs, name, device)\u001b[0m\n\u001b[0;32m     30\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     33\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name = \"fft_alex\"\n",
    "tr_acc_list, val_acc_list = train(model, train_dl, val_dl, loss_fn, optimizer, scheduler, epochs=epochs, name=name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef07db8-bb4b-4278-8a2c-d230d63babe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T05:07:41.883936Z",
     "start_time": "2025-02-03T05:07:41.235486Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_accuracy = np.array(tr_acc_list, dtype=np.float32)\n",
    "val_accuracy = np.array(val_acc_list, dtype=np.float32)\n",
    "np.save(os.path.join('models', 'alex', 'tr_fft_accuracy.npy'), tr_accuracy)\n",
    "np.save(os.path.join('models', 'alex', 'val_fft_accuracy.npy'), val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eb937-7117-4658-b432-3a84c651acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
