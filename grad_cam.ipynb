{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bedbeef-4bac-45b7-9ab9-abbd5660b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c2f879-1f56-4dfd-8a61-219772133272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0637bbc8-a16d-4f04-beca-61f15bde06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.FFTConv import *\n",
    "from src.ImageHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f589373b-fdfa-458c-bd50-6acf4d3b2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 129\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "targets = ['bacterial', 'normal', 'viral']\n",
    "REBUILD_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69695ae7-36e8-4e56-a5d1-4de819454b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Layers replaced:  1\n"
     ]
    }
   ],
   "source": [
    "model = FFTAlex(apply_fft=True, device=device, IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc9fcf-31a0-4d16-9f6c-93fbc9e9dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FFTGoogle(apply_fft=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9b49fa-1ff8-4489-865f-dc223f8dba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFTAlex(\n",
       "  (model): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): FFTConvNet(\n",
       "        (conv_layer): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU()\n",
       "      (10): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU()\n",
       "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_model_dict(os.path.join('models', 'alex', 'fft_alex_model.pth'))\n",
    "model.eval()\n",
    "# layer = model.model.inception4e.branch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016d282-b910-4dd3-8cd0-5cc1d6f069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook to store the feature maps\n",
    "feature_maps = None\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    global feature_maps\n",
    "    feature_maps = output\n",
    "\n",
    "# Register the hook to the last convolutional layer\n",
    "layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d481e58-dd9d-49d8-861b-bec4db5837db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmdb_path = os.path.join('lmdb')\n",
    "\n",
    "# if REBUILD_DATA:\n",
    "#     image_path = os.path.join('data', 'test_set')\n",
    "#     test_data = ImageDataset(image_path=image_path, device=device, lmdb_path=lmdb_path, save_lmdb=True, mode=\"test\")\n",
    "\n",
    "#     REBUILD_DATA = False\n",
    "# else:\n",
    "#     test_data = ImageDataset(image_path=None, device=device, lmdb_path=lmdb_path, save_lmdb=False, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095ba86-2191-40a5-bb28-9ccd99a6ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887c9e7-159f-4839-95d5-5a24815a8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, test_dl, device):\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     all_grads = []\n",
    "\n",
    "#     for images, labels in tqdm(test_dl):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         images.requires_grad = True  # Enable gradient tracking for images\n",
    "#         outputs = model(images)\n",
    "#         _, predicted_class = torch.max(outputs, dim=1)\n",
    "\n",
    "#         # Compute scalar loss to enable autograd\n",
    "#         loss = outputs.gather(1, predicted_class.view(-1, 1)).sum()\n",
    "#         model.zero_grad()\n",
    "#         loss.backward(retain_graph=True)\n",
    "\n",
    "#         # Store results\n",
    "#         all_preds.extend(predicted_class.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "#         all_grads.extend(images.grad.cpu().numpy())  # Save gradient maps\n",
    "\n",
    "#     return np.array(all_labels), np.array(all_preds), np.array(all_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf4bd1-c3bb-4ffc-8117-e19bb1803279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, preds, grads = test(model, test_dl, device)\n",
    "\n",
    "# for i in range(len(grads)):  \n",
    "#     gradients = grads[i]  # Select gradients for the i-th sample\n",
    "\n",
    "#     # Follow the same heatmap generation pipeline\n",
    "#     pooled_gradients = torch.mean(torch.Tensor(gradients), dim=[0, 2, 3])  # Pool over spatial dimensions\n",
    "#     pooled_gradients = pooled_gradients.detach().cpu().numpy()\n",
    "#     feature_maps = feature_maps.cpu()\n",
    "#     for j in range(feature_maps.shape[1]):\n",
    "#         feature_maps[:, j, :, :] *= pooled_gradients[j]\n",
    "\n",
    "\n",
    "#     heatmap = torch.mean(feature_maps, dim=1).squeeze()\n",
    "#     heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)\n",
    "#     heatmap /= np.max(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdd919-5a7a-4c34-b607-97c26acca15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, )\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    preprocess = v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.5,], std=[0.5,]),\n",
    "        v2.Grayscale(num_output_channels=3)\n",
    "    ])\n",
    "    img = preprocess(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "img_path = os.path.join(\"image.jpeg\")\n",
    "input_image = preprocess_image(img_path).to(device)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_image)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted_class = torch.max(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f52bf-6e78-426c-96ec-7cd76a563fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero the gradients\n",
    "model.model.zero_grad()\n",
    "\n",
    "# Get the gradients of the output with respect to the feature maps\n",
    "gradients = torch.autograd.grad(output[:, predicted_class], feature_maps, retain_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33216b-5202-49d3-8d98-3de2eb4e6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# Weight the feature maps by the pooled gradients\n",
    "for i in range(feature_maps.shape[1]):\n",
    "    feature_maps[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# Average the feature maps along the channel dimension\n",
    "heatmap = torch.mean(feature_maps, dim=1).squeeze()\n",
    "\n",
    "# Apply ReLU to the heatmap\n",
    "heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)\n",
    "\n",
    "# Normalize the heatmap\n",
    "heatmap /= np.max(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3554e5-0d95-48a6-8f7c-3303a9b35147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(dataset)):  \n",
    "#     image_tensor, label = dataset[i]  # Retrieve preprocessed image and label\n",
    "#     img = (image_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)  # Convert tensor to NumPy image\n",
    "    \n",
    "#     # Get heatmap for the corresponding image\n",
    "#     heatmap = grads[i]  # Extract stored gradients\n",
    "#     heatmap = np.mean(heatmap, axis=0)  # Pool gradients across channels\n",
    "#     heatmap = np.maximum(heatmap, 0)  # Apply ReLU\n",
    "#     heatmap /= np.max(heatmap)  # Normalize\n",
    "\n",
    "#     # Resize heatmap to match the original image size\n",
    "#     heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "#     # Convert heatmap to RGB\n",
    "#     heatmap = np.uint8(255 * heatmap)\n",
    "#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "#     # Superimpose the heatmap on the original image\n",
    "#     superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "#     # Display the image\n",
    "#     plt.imshow(superimposed_img / 255)\n",
    "#     plt.title(f\"Prediction: {targets[preds[i]]}\")  # Use model predictions\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b88fc-d580-48bf-8d18-440c041fed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# Resize the heatmap to match the image size\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# Convert the heatmap to RGB\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# Superimpose the heatmap on the original image\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(superimposed_img / 255)\n",
    "plt.title(f\"Prediction: {targets[predicted_class]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7dcf9a-0bee-452b-a31e-4ad72433aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda:nvidia",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
